{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: A deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_36/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[ 0.29022652, -0.16749294,  0.29200178,  0.25542766, -0.07026188,\n",
       "         -0.17865497,  0.03647417, -0.2686273 , -0.0397284 , -0.28567168,\n",
       "          0.22868007, -0.15773462,  0.13961792,  0.24065101, -0.1610338 ,\n",
       "          0.17782569, -0.1767084 , -0.1151541 ,  0.24811518,  0.24463052,\n",
       "         -0.18884465,  0.01135388, -0.17383951,  0.22105145, -0.13538153,\n",
       "          0.00957334, -0.06541446, -0.26486635, -0.24652249,  0.00579861,\n",
       "          0.23209798, -0.03000781, -0.14979029,  0.19797921, -0.13314779,\n",
       "         -0.19112435,  0.262887  ,  0.12215787,  0.09824669, -0.08829765,\n",
       "         -0.00132307, -0.10410346,  0.28476924, -0.01492468,  0.15818202,\n",
       "         -0.27656618, -0.20893967,  0.24940205, -0.2108629 ,  0.0170536 ,\n",
       "         -0.1583146 , -0.10365468,  0.0226182 ,  0.0480786 , -0.20815341,\n",
       "          0.07886609,  0.02107766,  0.24055636,  0.16712186, -0.08866738,\n",
       "         -0.02846527, -0.11866833, -0.06440353, -0.26058948],\n",
       "        [-0.16054505, -0.08071306,  0.14425352,  0.26528805,  0.27486086,\n",
       "          0.03770104, -0.11332026,  0.24885094, -0.24491203,  0.02788559,\n",
       "          0.08968288,  0.252783  , -0.22570117, -0.18165277,  0.06008345,\n",
       "         -0.23555419,  0.01221618, -0.04194579, -0.11035414,  0.26113117,\n",
       "          0.07757393, -0.27543876,  0.03671789, -0.15433034,  0.2685849 ,\n",
       "         -0.1288466 , -0.18684258, -0.25872013,  0.04508767, -0.04209742,\n",
       "          0.25226176,  0.21287751, -0.23508635, -0.25357434, -0.02038154,\n",
       "          0.28235   , -0.12411542,  0.25971222, -0.00102463,  0.22874278,\n",
       "          0.22858047,  0.03098476,  0.24503255, -0.12758447, -0.16245496,\n",
       "          0.12590268, -0.2758114 , -0.18715358,  0.01101691, -0.0278621 ,\n",
       "          0.03265694,  0.2536028 ,  0.10800874, -0.1719102 ,  0.09591386,\n",
       "          0.24583936, -0.19628897, -0.2563067 ,  0.01077867,  0.17454335,\n",
       "          0.10595858,  0.2241351 , -0.09870374,  0.1305247 ],\n",
       "        [-0.26483846,  0.03948939,  0.2888431 ,  0.05731925, -0.07083222,\n",
       "          0.24254447, -0.22346878,  0.01660404,  0.01426092, -0.09279354,\n",
       "          0.12212467, -0.26918834,  0.14529961,  0.18547934, -0.21833932,\n",
       "         -0.0018295 ,  0.27665436, -0.23077333, -0.127177  ,  0.29405606,\n",
       "         -0.18572043,  0.03288019,  0.29475743,  0.22120982,  0.09171605,\n",
       "          0.24119765, -0.24466461,  0.2540679 , -0.22844854, -0.11494856,\n",
       "          0.1412966 ,  0.03337803,  0.13931513,  0.0066376 ,  0.05478233,\n",
       "         -0.06980304, -0.14840372, -0.19180122, -0.06694651, -0.06133495,\n",
       "          0.2775336 ,  0.17192903,  0.02201617, -0.19533029,  0.02186155,\n",
       "         -0.10004522,  0.19138113,  0.19416833,  0.2532856 ,  0.24442059,\n",
       "          0.04803339, -0.20653097, -0.18633452, -0.00655797, -0.09910215,\n",
       "          0.04522693, -0.1679248 ,  0.09544438, -0.02031133,  0.18338194,\n",
       "         -0.2443205 ,  0.08698228,  0.12393185,  0.1150752 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_36/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_37/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[-0.26182473, -0.05423896, -0.23420778,  0.01926529, -0.18371794,\n",
       "          0.17879665,  0.2625247 , -0.25777453,  0.00951982,  0.19940907],\n",
       "        [-0.13901061,  0.23194054, -0.11216082, -0.11097528, -0.00593534,\n",
       "          0.22723082, -0.00807223,  0.10181582, -0.20922962, -0.06075244],\n",
       "        [-0.02168432,  0.23154911, -0.19744015, -0.14985386,  0.23462388,\n",
       "          0.25653335, -0.27974147,  0.06314397,  0.24536279, -0.20856568],\n",
       "        [ 0.11246502,  0.07399887, -0.08563934,  0.2565389 ,  0.05217487,\n",
       "          0.06608072, -0.05908385, -0.08362202,  0.24121621,  0.03064403],\n",
       "        [ 0.110001  ,  0.20531881, -0.07295203, -0.12337399,  0.02464408,\n",
       "          0.12187752,  0.04818583,  0.03259668,  0.04903477,  0.20437807],\n",
       "        [ 0.27245155, -0.27434915, -0.03795019,  0.13803259, -0.07729198,\n",
       "          0.25546005, -0.17257123, -0.23945716,  0.06352231,  0.1678488 ],\n",
       "        [-0.0423997 ,  0.16502732, -0.07903259, -0.24276385, -0.26877084,\n",
       "         -0.24157917, -0.05475755,  0.07463229, -0.26761532,  0.25946215],\n",
       "        [ 0.04205966, -0.26781008, -0.15777366, -0.04029901, -0.0986035 ,\n",
       "          0.1543428 , -0.08892497,  0.17358047,  0.2830294 ,  0.01585045],\n",
       "        [ 0.16381511,  0.2519894 , -0.18813553,  0.07370424,  0.25519165,\n",
       "          0.05594963,  0.13247949,  0.11641732, -0.01352641, -0.09368005],\n",
       "        [-0.10801083,  0.18295309, -0.14808494,  0.21570596, -0.12079984,\n",
       "         -0.11656451, -0.04233386,  0.09261101,  0.20669648, -0.19691774],\n",
       "        [-0.2514586 , -0.03258362,  0.06258422, -0.09320857, -0.08426127,\n",
       "          0.07071543,  0.22006819, -0.2692927 , -0.13562205, -0.01286519],\n",
       "        [ 0.02995715, -0.12458044,  0.26401654, -0.13937333,  0.06613725,\n",
       "          0.11892915,  0.04166421, -0.2527802 , -0.2163975 , -0.0114947 ],\n",
       "        [ 0.17980677, -0.1047415 ,  0.01399684,  0.19631368, -0.09190354,\n",
       "          0.26577404,  0.0026271 ,  0.06814575,  0.27044937, -0.04780714],\n",
       "        [-0.16094503,  0.02324155, -0.14309332, -0.03263813,  0.12851197,\n",
       "         -0.22537799,  0.04563951,  0.150022  , -0.2845609 ,  0.24102291],\n",
       "        [-0.13843545, -0.0380453 ,  0.26841274, -0.02133101, -0.12444453,\n",
       "         -0.1842954 , -0.1585465 , -0.242899  , -0.23155916,  0.09385875],\n",
       "        [ 0.0657748 ,  0.04981476,  0.09324047,  0.19241676, -0.26718837,\n",
       "         -0.12503102, -0.14761446,  0.20882785,  0.15453094, -0.16840935],\n",
       "        [-0.04123452,  0.06652659, -0.2810135 , -0.24167062,  0.09615964,\n",
       "         -0.04550028, -0.20233671,  0.23902479, -0.09406513,  0.01181921],\n",
       "        [-0.25998914,  0.2813376 ,  0.1255345 , -0.157263  ,  0.09161088,\n",
       "          0.07708851,  0.19287264, -0.2386218 ,  0.14428267, -0.26442373],\n",
       "        [ 0.07887283,  0.05241185,  0.00221169, -0.1791065 , -0.06832241,\n",
       "         -0.16287395, -0.05484581,  0.03391927, -0.10639602, -0.2523352 ],\n",
       "        [ 0.06668648,  0.22588196, -0.11331601,  0.03924525, -0.2676092 ,\n",
       "         -0.10660234,  0.13819751, -0.27222905,  0.25586888,  0.21733186],\n",
       "        [ 0.0368889 ,  0.08340281,  0.1866326 , -0.0378855 , -0.1214771 ,\n",
       "          0.18741009,  0.08564946,  0.05460888,  0.10081974,  0.27987972],\n",
       "        [-0.18134943, -0.18977466,  0.14221525, -0.22047403,  0.07738572,\n",
       "         -0.03771177, -0.19478658,  0.0108712 , -0.0004116 ,  0.10234061],\n",
       "        [-0.22088006,  0.03092578,  0.06896198, -0.11660755,  0.1590806 ,\n",
       "         -0.05647664,  0.02554721, -0.16176742, -0.0932764 , -0.02168071],\n",
       "        [-0.14630447, -0.10236409, -0.19510742, -0.07375319,  0.23143056,\n",
       "          0.16245615,  0.09018338,  0.1644809 ,  0.06389135, -0.02597883],\n",
       "        [ 0.08980978,  0.05537251, -0.22730577,  0.19741565,  0.25789347,\n",
       "          0.16003585,  0.25548473,  0.08860093, -0.05441464, -0.16867243],\n",
       "        [ 0.16329569,  0.21733424,  0.23715195,  0.1361719 ,  0.08794078,\n",
       "         -0.23901719, -0.23722626,  0.00237393,  0.10365975,  0.22345224],\n",
       "        [ 0.16837418,  0.26959512, -0.18549418, -0.06399664, -0.01294005,\n",
       "          0.04393786, -0.0363417 , -0.24593344, -0.20125952,  0.25254896],\n",
       "        [ 0.27684465, -0.14429224, -0.08228338, -0.0568964 , -0.09153599,\n",
       "         -0.04169841, -0.14714399,  0.03709581,  0.1165626 ,  0.00153619],\n",
       "        [-0.03013277, -0.08364598, -0.10597558,  0.18665215,  0.09096998,\n",
       "          0.1151081 ,  0.10602278, -0.26478195, -0.15246506, -0.2750417 ],\n",
       "        [-0.23491058,  0.07739341, -0.25326934,  0.11020005, -0.12922725,\n",
       "         -0.03831333, -0.04585411,  0.21968135, -0.03313524,  0.15464199],\n",
       "        [ 0.15149072, -0.07469957,  0.2656615 , -0.10947405,  0.25068024,\n",
       "          0.08877119,  0.05875602, -0.07227966,  0.21085128, -0.27833447],\n",
       "        [-0.06850998,  0.15669149, -0.11422309, -0.13033201, -0.09854044,\n",
       "         -0.19703689, -0.1577744 , -0.09931722, -0.11980547,  0.10121635],\n",
       "        [-0.07590745, -0.201764  ,  0.07758737,  0.24673721, -0.23042636,\n",
       "         -0.18025227,  0.03540781,  0.17250273, -0.20728149,  0.15988094],\n",
       "        [ 0.21002659,  0.17880875,  0.06961209,  0.12346056,  0.00064263,\n",
       "          0.13488173,  0.20712635, -0.1144273 , -0.18368724, -0.18823019],\n",
       "        [ 0.04951543, -0.12771916,  0.14962798,  0.1231598 , -0.03504251,\n",
       "         -0.10778204,  0.26994553,  0.02972266, -0.28438798, -0.09769747],\n",
       "        [ 0.06414181,  0.03970656, -0.05484256,  0.274044  , -0.03497455,\n",
       "          0.06965968,  0.01975593, -0.10020263,  0.25203028,  0.14068347],\n",
       "        [ 0.09529793, -0.08015886, -0.18096817,  0.00664905, -0.12776844,\n",
       "          0.0767577 ,  0.06948134,  0.06763741, -0.16107428,  0.18703738],\n",
       "        [ 0.22676125,  0.12124607,  0.04459015,  0.1660716 ,  0.10315996,\n",
       "         -0.23027992, -0.15341435,  0.19867307, -0.08730724, -0.05060315],\n",
       "        [-0.11421603, -0.05935487, -0.14544384, -0.10843745, -0.09810032,\n",
       "         -0.23618886, -0.13171281, -0.15368557, -0.18323219,  0.16868022],\n",
       "        [-0.09687418, -0.06875628, -0.22299482, -0.07289915,  0.14690313,\n",
       "         -0.03171676,  0.22892335, -0.1558342 ,  0.2810214 , -0.04620245],\n",
       "        [-0.22240737,  0.05598304,  0.25525185, -0.25337797,  0.2801917 ,\n",
       "         -0.00617471, -0.07417783, -0.12886955, -0.26328692,  0.14491016],\n",
       "        [ 0.03047636,  0.23450711, -0.20568323,  0.2426506 ,  0.05530766,\n",
       "         -0.09730195, -0.15814549, -0.06067084,  0.22504881,  0.01146722],\n",
       "        [-0.07776897, -0.06779531,  0.0976299 , -0.09171562, -0.2472765 ,\n",
       "          0.15831956, -0.23749341, -0.11889955,  0.14009929,  0.23270103],\n",
       "        [ 0.24779019, -0.2736865 , -0.2196159 , -0.26479107, -0.22181043,\n",
       "          0.1980528 , -0.06460215, -0.01159695, -0.26465976, -0.00327885],\n",
       "        [-0.09079273, -0.20247881, -0.0722453 , -0.09836468, -0.03009659,\n",
       "          0.16034299, -0.08376554,  0.13726193,  0.28186253, -0.01861444],\n",
       "        [-0.14868283, -0.18861309, -0.01011628, -0.1038563 , -0.09779482,\n",
       "          0.08629319,  0.18270415, -0.15576787, -0.03683566,  0.00321612],\n",
       "        [ 0.23074362,  0.11448553, -0.13112576,  0.26480213, -0.12199429,\n",
       "         -0.03712344,  0.21570083,  0.05760443,  0.0579457 ,  0.06637651],\n",
       "        [ 0.19632208, -0.17737472, -0.05418471,  0.04634222, -0.03642337,\n",
       "          0.13924977, -0.09893535, -0.14946458,  0.27496228,  0.23498389],\n",
       "        [ 0.16765639,  0.10073075, -0.15612042, -0.25549847,  0.22007194,\n",
       "          0.1606026 , -0.2520725 ,  0.20536694, -0.06993116, -0.19719487],\n",
       "        [-0.263295  , -0.23335719, -0.07091624, -0.04090765,  0.2388005 ,\n",
       "          0.04131362, -0.26819944,  0.01452038,  0.08676338, -0.20070331],\n",
       "        [ 0.09093586, -0.02053863,  0.24713227,  0.2621254 , -0.13604467,\n",
       "          0.19559479,  0.128247  , -0.07178698, -0.17176947,  0.08368447],\n",
       "        [ 0.07047027, -0.0578793 ,  0.1273453 , -0.05468519,  0.2677743 ,\n",
       "          0.14600453,  0.13375673, -0.25643066,  0.26474485, -0.17314348],\n",
       "        [-0.00325224,  0.11196849, -0.0256438 , -0.11850934,  0.0806081 ,\n",
       "         -0.22432598,  0.18436533,  0.15516767,  0.17724568,  0.0991748 ],\n",
       "        [-0.14476603,  0.03048342,  0.13865438,  0.16983673,  0.10950893,\n",
       "          0.19392607,  0.2531323 ,  0.21997163, -0.22261783, -0.05217241],\n",
       "        [-0.0558968 ,  0.2813693 ,  0.06699485, -0.00628394,  0.14807707,\n",
       "         -0.19774775, -0.25580657,  0.00161549, -0.11255953, -0.24202032],\n",
       "        [-0.13613835, -0.0679778 , -0.03744034, -0.12873954, -0.27586275,\n",
       "         -0.05618948,  0.14952037,  0.16828626,  0.16912967, -0.1491863 ],\n",
       "        [-0.24582557,  0.23608956, -0.26977256, -0.2675204 , -0.2197318 ,\n",
       "         -0.05500127, -0.27357367, -0.00055519, -0.14508282, -0.142894  ],\n",
       "        [-0.1161457 ,  0.07259947, -0.10932313, -0.20429897, -0.17330545,\n",
       "         -0.24475007,  0.05596137,  0.05842397,  0.13520706,  0.08153328],\n",
       "        [ 0.21453774,  0.15420684, -0.19231418,  0.24623105,  0.10259369,\n",
       "          0.22411689,  0.22109792,  0.22806123,  0.12536755, -0.24281578],\n",
       "        [ 0.02270788, -0.07501525,  0.20007437, -0.03726472,  0.2544866 ,\n",
       "         -0.18211922,  0.00481844,  0.06906456,  0.22055045, -0.26660287],\n",
       "        [ 0.230526  ,  0.16105977,  0.03254059,  0.12760723,  0.19045421,\n",
       "         -0.00227672, -0.06368741, -0.01748973, -0.22412089, -0.04859431],\n",
       "        [ 0.04956561,  0.19983208, -0.20900857,  0.1654126 ,  0.10369641,\n",
       "         -0.16432746, -0.14420846, -0.18857472,  0.17507666,  0.14758167],\n",
       "        [ 0.05787367, -0.23856531,  0.2193251 , -0.01668361,  0.11830112,\n",
       "          0.03913677, -0.03794612, -0.14989357, -0.03311467, -0.23284477],\n",
       "        [ 0.2533963 , -0.24281564, -0.09918539, -0.1169901 ,  0.1844658 ,\n",
       "          0.08783278,  0.12334162, -0.05432625,  0.25931707, -0.01083842]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_37/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_first_layer (Dense)       (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "my_last_layer (Dense)        (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 64)                256       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_input (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 10ms/step - loss: 21.7478 - priority_loss: 0.3210 - department_loss: 21.4269 - priority_mean_absolute_error: 0.4893 - department_accuracy: 0.2523\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 28.8471 - priority_loss: 0.3254 - department_loss: 28.5217 - priority_mean_absolute_error: 0.4946 - department_accuracy: 0.1344\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 9ms/step - loss: 28.2570 - priority_loss: 0.3254 - department_loss: 27.9317 - priority_mean_absolute_error: 0.4946 - department_accuracy: 0.2453\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 37.5375 - priority_loss: 0.3254 - department_loss: 37.2122 - priority_mean_absolute_error: 0.4946 - department_accuracy: 0.1344\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x1a8189c7fa0>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x1a8189c7eb0>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x1a8189c7490>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x1a8189c7c70>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a8189c72b0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a820afec10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a820afe3a0>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate_2')>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 10ms/step - loss: 38.5000 - output_1_loss: 0.3287 - output_2_loss: 38.1713 - output_1_mean_absolute_error: 0.4980 - output_2_accuracy: 0.2984\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 16.6385 - output_1_loss: 0.3363 - output_2_loss: 16.3023 - output_1_mean_absolute_error: 0.5054 - output_2_accuracy: 0.0711\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2940 - accuracy: 0.9133 - val_loss: 0.1594 - val_accuracy: 0.9550\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1638 - accuracy: 0.9546 - val_loss: 0.1129 - val_accuracy: 0.9695\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1375 - accuracy: 0.9640 - val_loss: 0.1108 - val_accuracy: 0.9700\n",
      "313/313 [==============================] - 0s 495us/step - loss: 0.1083 - accuracy: 0.9729\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2966 - accuracy: 0.9120 - rmse: 7.1828 - val_loss: 0.1547 - val_accuracy: 0.9571 - val_rmse: 7.3598\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1690 - accuracy: 0.9525 - rmse: 7.3553 - val_loss: 0.1219 - val_accuracy: 0.9668 - val_rmse: 7.4020\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1419 - accuracy: 0.9616 - rmse: 7.3861 - val_loss: 0.1130 - val_accuracy: 0.9698 - val_rmse: 7.4202\n",
      "313/313 [==============================] - 0s 550us/step - loss: 0.0996 - accuracy: 0.9741 - rmse: 7.4327\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2929 - accuracy: 0.9134 - val_loss: 0.1640 - val_accuracy: 0.9509\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1632 - accuracy: 0.9539 - val_loss: 0.1307 - val_accuracy: 0.9650\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1396 - accuracy: 0.9623 - val_loss: 0.1215 - val_accuracy: 0.9687\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1276 - accuracy: 0.9672 - val_loss: 0.1046 - val_accuracy: 0.9741\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1156 - accuracy: 0.9708 - val_loss: 0.1101 - val_accuracy: 0.9738\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1117 - accuracy: 0.9724 - val_loss: 0.1099 - val_accuracy: 0.9742\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1058 - accuracy: 0.9750 - val_loss: 0.1161 - val_accuracy: 0.9760\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0986 - accuracy: 0.9762 - val_loss: 0.1085 - val_accuracy: 0.9788\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0963 - accuracy: 0.9772 - val_loss: 0.1183 - val_accuracy: 0.9770\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0969 - accuracy: 0.9778 - val_loss: 0.1207 - val_accuracy: 0.9789\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0940 - accuracy: 0.9792 - val_loss: 0.1302 - val_accuracy: 0.9773\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0920 - accuracy: 0.9807 - val_loss: 0.1273 - val_accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a81d558ee0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=20,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2952 - accuracy: 0.9122 - val_loss: 0.1519 - val_accuracy: 0.9564\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1631 - accuracy: 0.9536 - val_loss: 0.1301 - val_accuracy: 0.9648\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1379 - accuracy: 0.9631 - val_loss: 0.1198 - val_accuracy: 0.9679\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1252 - accuracy: 0.9682 - val_loss: 0.1033 - val_accuracy: 0.9729\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1151 - accuracy: 0.9703 - val_loss: 0.1058 - val_accuracy: 0.9755\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1086 - accuracy: 0.9727 - val_loss: 0.1044 - val_accuracy: 0.9755\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1054 - accuracy: 0.9756 - val_loss: 0.1143 - val_accuracy: 0.9748\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1015 - accuracy: 0.9758 - val_loss: 0.1187 - val_accuracy: 0.9755\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0955 - accuracy: 0.9781 - val_loss: 0.1208 - val_accuracy: 0.9782\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0902 - accuracy: 0.9790 - val_loss: 0.1241 - val_accuracy: 0.9769\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0899 - accuracy: 0.9792 - val_loss: 0.1153 - val_accuracy: 0.9796\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0884 - accuracy: 0.9805 - val_loss: 0.1233 - val_accuracy: 0.9777\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0823 - accuracy: 0.9815 - val_loss: 0.1354 - val_accuracy: 0.9785\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0840 - accuracy: 0.9814 - val_loss: 0.1204 - val_accuracy: 0.9801\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0850 - accuracy: 0.9829 - val_loss: 0.1187 - val_accuracy: 0.9815\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0791 - accuracy: 0.9826 - val_loss: 0.1309 - val_accuracy: 0.9798\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0759 - accuracy: 0.9835 - val_loss: 0.1331 - val_accuracy: 0.9801\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0741 - accuracy: 0.9843 - val_loss: 0.1351 - val_accuracy: 0.9793\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0750 - accuracy: 0.9839 - val_loss: 0.1385 - val_accuracy: 0.9803\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0741 - accuracy: 0.9849 - val_loss: 0.1398 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a81d6970d0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAGwCAYAAABCV9SaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPC0lEQVR4nO3deVyU1eI/8M/sw7AMArIpm6KoqGjgglpqKi5122+k5XKzxcrKLFPDzKyutli2aVfrq9mmpXV/pd4MrcxEMxFKc19BBRHZt1nP7w9kcgQUcIZ5YD7v12teNc+c5zznDDjz4ZzzPI9MCCFARERE1MrJXd0AIiIioubA0ENERERugaGHiIiI3AJDDxEREbkFhh4iIiJyCww9RERE5BYYeoiIiMgtKF3dgOZmtVpx9uxZeHt7QyaTubo5RERE1ABCCJSWliI0NBRyedPGbNwu9Jw9exZhYWGubgYRERE1QXZ2Ntq3b9+kfd0u9Hh7ewOoftN8fHxc3BoiIiJqiJKSEoSFhdm+x5vC7UJPzZSWj48PQw8REVELcy1LU7iQmYiIiNwCQw8RERG5BYYeIiIicgtut6aHiNyDxWKByWRydTOIqBHUanWTT0dvCIYeImpVhBDIzc1FUVGRq5tCRI0kl8sRFRUFtVrtlPoZeoioVakJPIGBgdDpdLwIKVELUXPx4JycHISHhzvl3y5DDxG1GhaLxRZ4/P39Xd0cImqktm3b4uzZszCbzVCpVA6vnwuZiajVqFnDo9PpXNwSImqKmmkti8XilPoZeoio1eGUFlHL5Ox/uww9RERE5BYYeoiIiMgtMPQQEbVSQ4YMwbRp0xpc/uTJk5DJZMjMzHRamwDg559/hkwmc9llBbZv344ePXpApVLhtttuc0kbrkVkZCQWL17cqH0a+7vgKM31O9VQPHvLQSxWgZziSgBA+zZcRElEDXe1dQwTJ07EypUrG13v119/3agzYMLCwpCTk4OAgIBGH6slmT59Onr16oX//e9/8PLycnVzWoyff/4ZQ4cORWFhIXx9fV3dnCZh6HGQC+UGDHr1J8hlwPEFN7m6OUTUguTk5Nj+f82aNZg7dy4OHTpk2+bh4WFX3mQyNSjM+Pn5NaodCoUCwcHBjdqnJTp27BimTJmC9u3bN7kOo9HotAvokfNweouIWjUhBCqM5mZ/CCEa3Mbg4GDbQ6/XQyaT2Z5XVVXB19cXX375JYYMGQKtVotPP/0UFy5cwNixY9G+fXvodDr06NEDX3zxhV29l09pREZG4t///jfuv/9+eHt7Izw8HMuWLbO9fvlURM001JYtW5CQkACdTocBAwbYBTIAePnllxEYGAhvb2888MADmDVrFnr16tWon9O6desQGxsLjUaDyMhILFq0yO71JUuWoFOnTtBqtQgKCsJdd91le23t2rXo0aMHPDw84O/vj+HDh6O8vLzWMWr6d+HCBdx///2QyWS2EbStW7eib9++0Gg0CAkJwaxZs2A2m+3ey6lTp2L69OkICAjAiBEj6u3LihUr0LVrV2i1WnTp0gVLliyxe33mzJno3LkzdDodOnTogOeff77WLVO+/fZbJCQkQKvVIiAgAHfccYfd6xUVFfX+HOtjNpsxdepU+Pr6wt/fH3PmzLH7Pf3000+RkJAAb29vBAcHY9y4ccjLy7O9d0OHDgUAtGnTBjKZDJMmTQJQfVHBV199FdHR0dBoNAgPD8crr7xid+zjx49j6NCh0Ol0iIuLw44dO67aXmfgSI+DNfxjjoiaQ6XJgm5zNzX7cffPHwmd2nEfsTNnzsSiRYuwYsUKaDQaVFVVIT4+HjNnzoSPjw82bNiA8ePHo0OHDujXr1+99SxatAgvvfQSnnvuOaxduxaPPPIIbrjhBnTp0qXefVJSUrBo0SK0bdsWU6ZMwf3334/t27cDAD777DO88sorWLJkCQYOHIjVq1dj0aJFiIqKanDf0tPTcffdd2PevHlITk5GWloaHn30Ufj7+2PSpEnYvXs3nnjiCXzyyScYMGAACgoKsG3bNgDVo2Rjx47Fa6+9httvvx2lpaXYtm1bnaGzZvouJiYG8+fPR3JyMvR6Pc6cOYMxY8Zg0qRJWLVqFQ4ePIgHH3wQWq0W8+bNs+3/8ccf45FHHsH27dvrDbXLly/HCy+8gPfeew+9e/dGRkYGHnzwQXh6emLixIkAAG9vb6xcuRKhoaHYu3cvHnzwQXh7e+PZZ58FAGzYsAF33HEHUlJS8Mknn8BoNGLDhg3X/HP8+OOPMXnyZPz222/YvXs3HnroIURERODBBx8EUD169dJLLyEmJgZ5eXl46qmnMGnSJGzcuBFhYWFYt24d7rzzThw6dAg+Pj62EcjZs2dj+fLleOuttzBo0CDk5OTg4MGDdsdOSUnBG2+8gU6dOiElJQVjx47F0aNHoVQ2cwwRbqa4uFgAEMXFxQ6tN6+kSkTMXC8iZ613aL1E1HCVlZVi//79orKy0rat3GASETPXN/uj3GBqUh9WrFgh9Hq97fmJEycEALF48eKr7jtmzBjx9NNP254PHjxYPPnkk7bnERER4r777rM9t1qtIjAwUCxdutTuWBkZGUIIIX766ScBQGzevNm2z4YNGwQA23vcr18/8dhjj9m1Y+DAgSIuLq7edtbUW1hYKIQQYty4cWLEiBF2ZWbMmCG6desmhBBi3bp1wsfHR5SUlNSqKz09XQAQJ0+erPd4l9Pr9WLFihW2588995yIiYkRVqvVtu39998XXl5ewmKxCCGq38tevXpdte6wsDDx+eef22176aWXRGJiYr37vPbaayI+Pt72PDExUdx77731lr/az7EugwcPFl27drXr48yZM0XXrl3r3WfXrl0CgCgtLRVC1P65CSFESUmJ0Gg0Yvny5XXWUfM79eGHH9q2/fXXXwKAOHDgQK3ydf0bruGI72+O9DhYI0a0iagZeKgU2D9/pEuO60gJCQl2zy0WCxYuXIg1a9bgzJkzMBgMMBgM8PT0vGI9PXv2tP1/zTRazRRGQ/YJCQkBAOTl5SE8PByHDh3Co48+ale+b9+++PHHHxvULwA4cOAAbr31VrttAwcOxOLFi2GxWDBixAhERESgQ4cOGDVqFEaNGoXbb7/dNlUybNgw9OjRAyNHjkRSUhLuuusutGnTplHHT0xMtFtQPnDgQJSVleH06dMIDw8HUPtncLnz588jOzsbkydPto2eANXTSnq93vZ87dq1WLx4MY4ePYqysjKYzWb4+PjYXs/MzLTbvy5N+Tn279/fro+JiYlYtGgRLBYLFAoFMjIyMG/ePGRmZqKgoABWqxUAkJWVhW7dutVZ54EDB2AwGDBs2LAGt/fS36ErjUw5A9f0OAgvAEskTTKZDDq1stkfjr6y7OVhZtGiRXjrrbfw7LPP4scff0RmZiZGjhwJo9F4xXouXwAtk8lsX24N2aemX5fuc3lfRSP/+hNCXLEOb29v7NmzB1988QVCQkIwd+5cxMXFoaioCAqFAqmpqfjf//6Hbt264d1330VMTAxOnDjhkONfuv1qgbLmPVm+fDkyMzNtj3379mHnzp0AgJ07d+Kee+7B6NGjsX79emRkZCAlJcXu53b5wvW6NOXneCXl5eVISkqCl5cXPv30U/z+++/45ptvAOCKv1MNaevl7a3rd6i5MPQQEbVA27Ztw6233or77rsPcXFx6NChA44cOdLs7YiJicGuXbvstu3evbtRdXTr1g2//vqr3ba0tDR07twZCkX1iJlSqcTw4cPx2muv4c8//8TJkydto0kymQwDBw7Eiy++iIyMDKjVatsXdkOPn5aWZhe00tLS4O3tjXbt2jW4nqCgILRr1w7Hjx9HdHS03aNmjdP27dsRERGBlJQUJCQkoFOnTjh16pRdPT179sSWLVsafNyGqglelz7v1KkTFAoFDh48iPz8fCxcuBDXX389unTpUmvkqK77YnXq1AkeHh5Oaa8zcHqLiKgFio6Oxrp165CWloY2bdrgzTffRG5uLrp27dqs7Xj88cfx4IMPIiEhAQMGDMCaNWvw559/okOHDg2u4+mnn0afPn3w0ksvITk5GTt27MB7771nO+tp/fr1OH78OG644Qa0adMGGzduhNVqRUxMDH777Tds2bIFSUlJCAwMxG+//Ybz58836n149NFHsXjxYjz++OOYOnUqDh06hBdeeAHTp0+HXN64sYF58+bhiSeegI+PD0aPHg2DwYDdu3ejsLAQ06dPR3R0NLKysrB69Wr06dMHGzZsqBXQXnjhBQwbNgwdO3bEPffcA7PZjP/973+2hc5NlZ2djenTp+Phhx/Gnj178O6779rOkgsPD4darca7776LKVOmYN++fXjppZfs9o+IiIBMJsP69esxZswYeHh4wMvLCzNnzsSzzz4LtVqNgQMH4vz58/jrr78wefLka2qvM3Ckx0E4u0VEzen555/Hddddh5EjR2LIkCEIDg52ydWF7733XsyePRvPPPMMrrvuOpw4cQKTJk2CVqttcB3XXXcdvvzyS6xevRrdu3fH3LlzMX/+fNsp0b6+vvj6669x4403omvXrvjggw/wxRdfIDY2Fj4+Pvjll18wZswYdO7cGXPmzMGiRYswevToBh+/Xbt22LhxI3bt2oW4uDhMmTIFkydPxpw5cxr7duCBBx7Ahx9+iJUrV6JHjx4YPHgwVq5caRvpufXWW/HUU09h6tSp6NWrF9LS0vD888/b1TFkyBB89dVX+Pbbb9GrVy/ceOON+O233xrdlstNmDABlZWV6Nu3Lx577DE8/vjjeOihhwAAbdu2xcqVK/HVV1+hW7duWLhwId544w27/du1a4cXX3wRs2bNQlBQEKZOnQqg+nfx6aefxty5c9G1a1ckJydfdX2Rq8hEYydfW7iSkhLo9XoUFxfbLRy7VhfKDIh/eTMA4ORCXpyQyBWqqqpw4sQJREVFNepLlxxrxIgRCA4OxieffOLqplALc6V/w474/ub0lhPUtSiOiKg1qqiowAcffICRI0dCoVDgiy++wObNm5GamurqphHVwtDjIAw5ROSOZDIZNm7ciJdffhkGgwExMTFYt24dhg8f7uqmEdXC0OMEQvAUdiJyDx4eHti8ebOrm0HUIFzI7CDMOETS4WZLFYlaDWf/23V56FmyZIltwVJ8fLztfip1qbn53eWPy+/xQUTuqeYCaBUVFS5uCRE1Rc2FEGuuz+RoLp3eWrNmDaZNm2a7Ud1//vMfjB49Gvv377dd9rsuNTc7q9G2bdvmaG6D8W9MItdQKBTw9fW1nS6r0+m43o6ohbBarTh//jx0Op3TbkTq0tDz5ptvYvLkyXjggQcAAIsXL8amTZuwdOlSLFiwoN79AgMD4evr20ytbBh+rhJJQ3BwMABI9johRFQ/uVyO8PBwp/2x4rLQYzQakZ6ejlmzZtltT0pKQlpa2hX37d27N6qqqtCtWzfMmTMHQ4cOrbdszU34apSUlFxbwxugek6SKYjIFWQyGUJCQhAYGAiTyeTq5hBRI6jV6kZfBbsxXBZ68vPzYbFYEBQUZLc9KCgIubm5de4TEhKCZcuWIT4+HgaDAZ988gmGDRuGn3/+GTfccEOd+yxYsAAvvviiw9t/ORlDDpGkKBQKp60LIKKWyeWnrNd1Z9v6hrViYmIQExNje56YmIjs7Gy88cYb9Yae2bNnY/r06bbnJSUlCAsLc0DLiYiIqCVx2dlbAQEBUCgUtUZ18vLyao3+XEn//v2veGdhjUYDHx8fu4ezcSEzERGR9Lgs9KjVasTHx9e6VHlqaioGDBjQ4HoyMjIQEhLi6OY1Hme3iIiIJM2l01vTp0/H+PHjkZCQgMTERCxbtgxZWVmYMmUKgOqpqTNnzmDVqlUAqs/uioyMRGxsLIxGIz799FOsW7cO69atc2U3auF10YiIiKTHpaEnOTkZFy5cwPz585GTk4Pu3btj48aNiIiIAADk5OQgKyvLVt5oNOKZZ57BmTNn4OHhgdjYWGzYsAFjxoxxVRdseMo6ERGRtMmEm12v3RG3pq+z3ioTes77AQBw+OXRUCtdfrFrIiKiVsMR39/8ZnYCwaXMREREksPQ4yCc3SIiIpI2hh4ncK8JQyIiopaBocdBeFNDIiIiaWPoISIiIrfA0ENERERugaHHQTi5RUREJG0MPUREROQWGHqcgGdvERERSQ9Dj4Pw5C0iIiJpY+hxAl6RmYiISHoYehxExqXMREREksbQQ0RERG6BoccJuJCZiIhIehh6HIQLmYmIiKSNoccJONBDREQkPQw9RERE5BYYeoiIiMgtMPQ4geBKZiIiIslh6HEQLmQmIiKSNoYeJ+A4DxERkfQw9DgIr8hMREQkbQw9RERE5BYYepyA65iJiIikh6HHQbiQmYiISNoYepyBIz1ERESSw9DjIBzoISIikjaGHiIiInILDD1OIDi/RUREJDkMPQ4i40pmIiIiSWPocQKesk5ERCQ9DD0OwnEeIiIiaWPoISIiIrfA0OMEnN0iIiKSHoYeB+E6ZiIiImlj6CEiIiK3wNDjBIKnbxEREUkOQ4+D8Do9RERE0sbQ4wQc5yEiIpIehh4iIiJyCww9RERE5BYYepyA65iJiIikh6HHgbiWmYiISLoYepxAcCkzERGR5DD0OBAHeoiIiKSLoYeIiIjcAkOPM3B2i4iISHIYehyIV2UmIiKSLoYeJ+BADxERkfQw9DgQx3mIiIiki6GHiIiI3AJDjxPwisxERETSw9DjQFzHTEREJF0MPU7AKzITERFJD0OPA8m4lJmIiEiyGHqIiIjILTD0OAEXMhMREUkPQ48jcXaLiIhIshh6nIADPURERNLD0ONAHOghIiKSLoYeIiIicgsuDz1LlixBVFQUtFot4uPjsW3btgbtt337diiVSvTq1cu5DWwCwZXMREREkuPS0LNmzRpMmzYNKSkpyMjIwPXXX4/Ro0cjKyvrivsVFxdjwoQJGDZsWDO1tGF4RWYiIiLpcmnoefPNNzF58mQ88MAD6Nq1KxYvXoywsDAsXbr0ivs9/PDDGDduHBITE5uppURERNTSuSz0GI1GpKenIykpyW57UlIS0tLS6t1vxYoVOHbsGF544YUGHcdgMKCkpMTu4Wyc3SIiIpIel4We/Px8WCwWBAUF2W0PCgpCbm5unfscOXIEs2bNwmeffQalUtmg4yxYsAB6vd72CAsLu+a214e3oSAiIpIuly9kll22EEYIUWsbAFgsFowbNw4vvvgiOnfu3OD6Z8+ejeLiYtsjOzv7mttMRERELU/DhkucICAgAAqFotaoTl5eXq3RHwAoLS3F7t27kZGRgalTpwIArFYrhBBQKpX44YcfcOONN9baT6PRQKPROKcTl+FCZiIiIuly2UiPWq1GfHw8UlNT7banpqZiwIABtcr7+Phg7969yMzMtD2mTJmCmJgYZGZmol+/fs3VdCIiImqBXDbSAwDTp0/H+PHjkZCQgMTERCxbtgxZWVmYMmUKgOqpqTNnzmDVqlWQy+Xo3r273f6BgYHQarW1trsaFzITERFJj0tDT3JyMi5cuID58+cjJycH3bt3x8aNGxEREQEAyMnJueo1e6SEs1tERETSJRNudvngkpIS6PV6FBcXw8fHx6F1x879HuVGC7bOGIIIf0+H1k1EROTOHPH97fKzt1qTus46IyIiImlg6CEiIiK3wNDjBO41YUhERNQyMPQ4ECe3iIiIpIuhxwk40ENERCQ9DD2OxKEeIiIiyWLoISIiIrfA0OMEbnbpIyIiohaBoceBOLtFREQkXQw9TsBxHiIiIulh6HEgXpGZiIhIuhh6iIiIyC0w9DgB1zETERFJD0OPA3F2i4iISLoYeoiIiMgtMPQ4Bee3iIiIpIahx4E4u0VERCRdDD1OwIXMRERE0sPQ40C8Tg8REZF0MfQQERGRW2DocQLObhEREUkPQ48DcXKLiIhIuhh6nIALmYmIiKSHoceBuI6ZiIhIuhh6iIiIyC0w9DiB4FJmIiIiyWHocSjObxEREUkVQ48TcCEzERGR9DD0OBAXMhMREUkXQw8RERG5BYYeJ+D0FhERkfQw9DgQZ7eIiIiki6HHCXjKOhERkfQw9DgQFzITERFJF0MPERERuQWGHifgQmYiIiLpYehxIBmXMhMREUkWQw8RERG5BYYeB+JCZiIiIuli6CEiIiK3wNDjBFzITEREJD0MPQ7E2S0iIiLpYughIiIit8DQ4wS8DQUREZH0MPQ4kIynbxEREUkWQ48TcCEzERGR9DD0EBERkVtg6CEiIiK3wNDjBJzdIiIikh6GHgfiOmYiIiLpYuhxAsGVzERERJLD0ONAHOkhIiKSLoYeIiIicgsMPU7AyS0iIiLpYehxIBlvOUpERCRZDD1OwHXMRERE0sPQ40BcyExERCRdDD1ERETkFhh6nILzW0RERFLD0ONAnN0iIiKSLoYeJ+BCZiIiIulpUujJzs7G6dOnbc937dqFadOmYdmyZY2ua8mSJYiKioJWq0V8fDy2bdtWb9lff/0VAwcOhL+/Pzw8PNClSxe89dZbTemCU8i4kpmIiEiymhR6xo0bh59++gkAkJubixEjRmDXrl147rnnMH/+/AbXs2bNGkybNg0pKSnIyMjA9ddfj9GjRyMrK6vO8p6enpg6dSp++eUXHDhwAHPmzMGcOXOaFLaIiIjIvTQp9Ozbtw99+/YFAHz55Zfo3r070tLS8Pnnn2PlypUNrufNN9/E5MmT8cADD6Br165YvHgxwsLCsHTp0jrL9+7dG2PHjkVsbCwiIyNx3333YeTIkVccHTIYDCgpKbF7OBtnt4iIiKSnSaHHZDJBo9EAADZv3oxbbrkFANClSxfk5OQ0qA6j0Yj09HQkJSXZbU9KSkJaWlqD6sjIyEBaWhoGDx5cb5kFCxZAr9fbHmFhYQ2quyk4uUVERCRdTQo9sbGx+OCDD7Bt2zakpqZi1KhRAICzZ8/C39+/QXXk5+fDYrEgKCjIbntQUBByc3OvuG/79u2h0WiQkJCAxx57DA888EC9ZWfPno3i4mLbIzs7u0HtuxZcyExERCQ9yqbs9Oqrr+L222/H66+/jokTJyIuLg4A8O2339qmvRrq8sW/QoirLgjetm0bysrKsHPnTsyaNQvR0dEYO3ZsnWU1Go1tVMrpONRDREQkWU0KPUOGDEF+fj5KSkrQpk0b2/aHHnoIOp2uQXUEBARAoVDUGtXJy8urNfpzuaioKABAjx49cO7cOcybN6/e0ENEREQENHF6q7KyEgaDwRZ4Tp06hcWLF+PQoUMIDAxsUB1qtRrx8fFITU21256amooBAwY0uC1CCBgMhoY3vhkIzm8RERFJTpNGem699VbccccdmDJlCoqKitCvXz+oVCrk5+fjzTffxCOPPNKgeqZPn47x48cjISEBiYmJWLZsGbKysjBlyhQA1etxzpw5g1WrVgEA3n//fYSHh6NLly4Aqq/b88Ybb+Dxxx9vSjccjrNbRERE0tWk0LNnzx7bRQHXrl2LoKAgZGRkYN26dZg7d26DQ09ycjIuXLiA+fPnIycnB927d8fGjRsREREBAMjJybG7Zo/VasXs2bNx4sQJKJVKdOzYEQsXLsTDDz/clG4QERGRG5GJJszF6HQ6HDx4EOHh4bj77rsRGxuLF154AdnZ2YiJiUFFRYUz2uoQJSUl0Ov1KC4uho+Pj0PrHrboZxw7X47VD/VH/w4NO4uNiIiIrs4R399NWtMTHR2N//73v8jOzsamTZts19rJy8tzeJBoSXgbCiIiIulqUuiZO3cunnnmGURGRqJv375ITEwEAPzwww/o3bu3QxvYEnEdMxERkfQ0aU3PXXfdhUGDBiEnJ8d2jR4AGDZsGG6//XaHNa6l4TgPERGRdDUp9ABAcHAwgoODcfr0achkMrRr167RFyYkIiIiai5Nmt6yWq2YP38+9Ho9IiIiEB4eDl9fX7z00kuwWq2ObmOLI3jLUSIiIslp0khPSkoKPvroIyxcuBADBw6EEALbt2/HvHnzUFVVhVdeecXR7WwRuI6ZiIhIupoUej7++GN8+OGHtrurA0BcXBzatWuHRx991G1Djw0HeoiIiCSnSdNbBQUFtqsiX6pLly4oKCi45ka1VDIuZSYiIpKsJoWeuLg4vPfee7W2v/fee+jZs+c1N4qIiIjI0Zo0vfXaa6/hpptuwubNm5GYmAiZTIa0tDRkZ2dj48aNjm5ji8PZLSIiIulp0kjP4MGDcfjwYdx+++0oKipCQUEB7rjjDvz1119YsWKFo9vYYnAhMxERkXQ1+To9oaGhtRYs//HHH/j444/xf//3f9fcsJaMV2QmIiKSniaN9BARERG1NAw9RERE5BYYepyAV2QmIiKSnkat6bnjjjuu+HpRUdG1tKXFk3ElMxERkWQ1KvTo9fqrvj5hwoRralBrwIXMRERE0tOo0OPOp6M3BMd5iIiIpItreoiIiMgtMPQ4AWe3iIiIpIehx4Fq1jELLuohIiKSHIYeB7KFHtc2g4iIiOrA0ONAcqYeIiIiyWLocaCas7eOnS9zaTuIiIioNoYeR7o40vPyhgPILa5ycWOIiIjoUgw9DnTpdXoO5JS4rB1ERERUG0OPA116Fwref4uIiEhaGHocSH5J6uFZ60RERNLC0ONAl05vMfQQERFJC0OPA9lPbxEREZGUMPQ4kAyXTm8x9hAREUkJQ48jcaSHiIhIshh6HIhreoiIiKSLoceBLj17i2M9RERE0sLQ40B2mYeIiIgkhaHHSTi9RUREJC0MPU7CzENERCQtDD0OdOnoDkd6iIiIpIWhx0l47y0iIiJpYehxEo70EBERSQtDj5Mw8xAREUkLQ48DXTqlxdtQEBERSQtDDxEREbkFhh4H4uAOERGRdDH0OAkDEBERkbQw9DgJT1knIiKSFoYeJ+FIDxERkbQw9DjQpTmHoYeIiEhaGHqchJmHiIhIWhh6nMTKoR4iIiJJYehxEl6ckIiISFoYehzpkpxjsbquGURERFQbQ4+TcHqLiIhIWhh6HOjSa/Mw9BAREUkLQ4+TWK0MPURERFLC0OMkZoYeIiIiSWHocZIqk8XVTSAiIqJLMPQ40KXLeKpMPH2LiIhIShh6nKSSIz1ERESSwtDjQJeu4uH0FhERkbS4PPQsWbIEUVFR0Gq1iI+Px7Zt2+ot+/XXX2PEiBFo27YtfHx8kJiYiE2bNjVjaxuO01tERETS4tLQs2bNGkybNg0pKSnIyMjA9ddfj9GjRyMrK6vO8r/88gtGjBiBjRs3Ij09HUOHDsU//vEPZGRkNHPLr67KzJEeIiIiKZEJF94kql+/frjuuuuwdOlS27auXbvitttuw4IFCxpUR2xsLJKTkzF37twGlS8pKYFer0dxcTF8fHya1O763Lk0DemnCgEAw7oE4qNJfRxaPxERkbtyxPe3y0Z6jEYj0tPTkZSUZLc9KSkJaWlpDarDarWitLQUfn5+9ZYxGAwoKSmxezjLpfnRYOb0FhERkZS4LPTk5+fDYrEgKCjIbntQUBByc3MbVMeiRYtQXl6Ou+++u94yCxYsgF6vtz3CwsKuqd0NZeIdR4mIiCTF5QuZZTKZ3XMhRK1tdfniiy8wb948rFmzBoGBgfWWmz17NoqLi22P7Ozsa25zQzD0EBERSYvSVQcOCAiAQqGoNaqTl5dXa/TncmvWrMHkyZPx1VdfYfjw4Vcsq9FooNForrm9jcXbUBAREUmLy0Z61Go14uPjkZqaarc9NTUVAwYMqHe/L774ApMmTcLnn3+Om266ydnNbJRLY46Ra3qIiIgkxWUjPQAwffp0jB8/HgkJCUhMTMSyZcuQlZWFKVOmAKiemjpz5gxWrVoFoDrwTJgwAW+//Tb69+9vGyXy8PCAXq93WT/qwuktIiIiaXFp6ElOTsaFCxcwf/585OTkoHv37ti4cSMiIiIAADk5OXbX7PnPf/4Ds9mMxx57DI899pht+8SJE7Fy5crmbn4tl578z+ktIiIiaXHpdXpcwZnX6bnt/e3IzC4CAITqtUibPcyh9RMREbmrFn2dntbOxJEeIiIiSWHocRKu6SEiIpIWhh4HunRsx8Szt4iIiCSFoceBLg06nN4iIiKSFoYeBzJeMqXF6S0iIiJpYehxIIPZYvt/IQALR3uIiIgkg6HHgS6/CjNHe4iIiKSDoceBDJeFHiNDDxERkWQw9DiQwWQfcswWTm8RERFJBUOPA126pgfg9BYREZGUMPQ40OXrlnmndSIiIulg6HGgJfdeZ/ecNx0lIiKSDoYeBxrTIwQHXxqFNjoVAE5vERERSQlDj4NpVQqoFNVvK0MPERGRdDD0OMHfoYfTW0RERFLB0OMEKoUMAEd6iIiIpIShxwk4vUVERCQ9DD1OoOT0FhERkeQw9DiBumZ6i9fpISIikgyGHidQK6vfVt57i4iISDoYepxAo1QAqH1bCiIiInIdhh4nsI30cHqLiIhIMhh6nEBzMfQYGHqIiIgkg6HHCTQc6SEiIpIchh4nUHOkh4iISHIYepzg74XMDD1ERERSwdDjBH+P9PDsLSIiIqlg6HECrukhIiKSHoYeJ+D0FhERkfQw9DiBbXrLxNBDREQkFQw9TqDhbSiIiIgkh6HHCf4e6eFCZiIiIqlg6HECjvQQERFJD0OPE2hUFxcyc00PERGRZDD0OIFawZEeIiIiqWHocQKNihcnJCIikhqGHifQKHhxQiIiIqlh6HGCv0d6GHqIiIikgqHHCWquyFxp5PQWERGRVDD0OIFOzdBDREQkNQw9TqBTKwEAFSYLhBAubg0REREBDD1O4XFxpMdiFTxtnYiISCIYepygZnoL4BQXERGRVDD0OIFKIYdKIQMAVDD0EBERSQJDj5N4XLwVBUMPERGRNDD0OEnNYmZObxEREUkDQ4+T6DQ1Iz1mF7eEiIiIAIYep6lZzMzpLSIiImlg6HESneritXoYeoiIiCSBocdJPNSc3iIiIpIShh4nsd2KwsSRHiIiIilg6HGSmrO3yg0MPURERFLA0OMk3tqa0MPpLSIiIilg6HESL0116Clj6CEiIpIEhh4n8bo40lNaxdBDREQkBQw9TvL3SI/JxS0hIiIigKHHaWrW9HB6i4iISBoYepzE8+LZW2Wc3iIiIpIEhh4nsa3p4UgPERGRJDD0OIltTQ9HeoiIiCSBocdJeJ0eIiIiaXF56FmyZAmioqKg1WoRHx+Pbdu21Vs2JycH48aNQ0xMDORyOaZNm9Z8DW2kmpGecqMFFqtwcWuIiIjIpaFnzZo1mDZtGlJSUpCRkYHrr78eo0ePRlZWVp3lDQYD2rZti5SUFMTFxTVzaxunZk0PAJTzpqNEREQu59LQ8+abb2Ly5Ml44IEH0LVrVyxevBhhYWFYunRpneUjIyPx9ttvY8KECdDr9c3c2sbRKBVQK6rfXq7rISIicj2XhR6j0Yj09HQkJSXZbU9KSkJaWprDjmMwGFBSUmL3aC5evFYPERGRZLgs9OTn58NisSAoKMhue1BQEHJzcx12nAULFkCv19seYWFhDqv7amrW9Uz++HecLqxotuMSERFRbS5fyCyTyeyeCyFqbbsWs2fPRnFxse2RnZ3tsLqvpib0ZBdUYsqn6c12XCIiIqpNefUizhEQEACFQlFrVCcvL6/W6M+10Gg00Gg0DquvMbwvWcy870zzTasRERFRbS4b6VGr1YiPj0dqaqrd9tTUVAwYMMBFrXKsNjq1q5tAREREF7lspAcApk+fjvHjxyMhIQGJiYlYtmwZsrKyMGXKFADVU1NnzpzBqlWrbPtkZmYCAMrKynD+/HlkZmZCrVajW7durujCFbXxZOghIiKSCpeGnuTkZFy4cAHz589HTk4Ounfvjo0bNyIiIgJA9cUIL79mT+/evW3/n56ejs8//xwRERE4efJkcza9QdroVK5uAhEREV3k0tADAI8++igeffTROl9buXJlrW1CtJyrG18+vWWyWKFSuHztOBERkVviN7ATXT699d6PR13UEiIiImLocaLLp7fe3nIE246cd1FriIiI3BtDjxPVtZA5I6uo+RtCREREDD3O1L6NR61txZUmF7SEiIiIGHqcqK1X7YsifvTrCby+6aALWkNEROTeGHqcSCaT4aspiRjTI9hu+/s/HUNJFUd8iIiImhNDj5P1ifTDe2OvQ1yYr9329FOFrmmQCwkhkF1Q0eDLDhw+V4pShkMiInIQhp5mIJfLsHJSH7ttv58ocFFrmp8QApv3n8OdS9Nw/Ws/4YGPd+PIuVIAwMa9OZjwf7uQfqoQlUYLygxmbD+aj28yTiPprV/Q95UteOarP+q8S/2ZokrsO1MMq1Wg0mhhQGoGQgiUG8y252lH8/Hb8Qt2770QAgazxRXNIyK6IploSVf7c4CSkhLo9XoUFxfDx8en2Y4rhEDU7I225x0CPPHd44PgqWne60MKIVBUYYLeQwW5vOl3s68wmlFcacLIt35B5yBvvPCPWOg0CnRs62UrU1plwmvfH8InO09dc7tVChnu6N0eiR39MSDaHyaLwMCFP9YqN7ZvGHw8VDiQUwoZgAAvDRIi22D/2RJ0CfHGnde1h1ohh0xWPf3oKFUmC0qqTPDRqqBVKfDX2WI8u/ZPdA7yRq8wX4T76xDkrYVGJceOYxfQo50ekf6e0Evwqt2VRgtUChmUCjn2nSnGd3+chV6nQqS/J7774yz+ty+3zv0i/HXo2NYLO49fQKXJglC9B9p4qtCjnS8i/XWwCiDUV4v2bXQwWazQe6hQbjAjMsATAZetf/t+Xy4OnytFqK8H2npr0DXEG4HeWgCA1Spsv7s1H1+X/yyNZisKK4wwmKwI1mtxIr8c246ch7+XGlEBXnhj0yHklxkQotciyEeL2HZ69A7zRZdgb+QUV+HbP85CpZDBV6dGWBsdQvRa5JcZkFdqAADoPVSQyQCNUgG9hwrtfD2gkMuQVVCOrIIKhOg9cCi3FAICvx0vQF6pAeF+OoT56S7+1wPt2+igkMmQfqoQxZUmaJRyhPhqEar3gLdWiZziKmiUcrTxVONcSRUM5ur3bG36aViFgK+HGicvlCPgYp86tvVEuJ8OSl4AlVopR3x/M/Q0owtlBsz9f39hw94c27bN029AdKB3s7Xhxe/+wortJ3F9pwB8ODEBGqWi0XW8mXoY72w5UudrI2ODEKL3wMq0k3W+rpDL0D3UB3+cLm7QsebfGotNf+Vi+9ELjW7nlQT5aHB3Qhi8tUoM7xqEDpeEtSspqTLhyLlSWKyAt1aJRT8cxu8nC2xn5clk1WftZRdUXrUumQzoG+mHPpF+6BTkBY1Sji7BPvDUKLH7ZAG2Hc3H9dEBCPTRINLfE/4Xg4HVWv1P9lpCa32+3nMa07/8AwAQ6a/DyQu1R9icwc9TDYPJAk+NElYB5JcZapUJ9tFCIZcht6QKkf46CAEczy+HViWHn04NnUYJP081KoxmHM0rQ5XJ2ixtlxK1Qo4ObT0RHeiF6EAvtG+jQxudCkE+WoTotThbVAWZDGjn6wFfnarO4C+EwJ6sIhRVGOHjoYKnWokygxkBXmr4e2ngpVFCIZdBCAGjxWr3GSKEwP6cEnhrVDBZq99/nVqBgnIjdGolgn208FArbGWtovozgVzHbKn+OV0als0WKxRyGapMVmQXVsDfUw0PtQIeKoVD/1hsLIaeJnBl6Kkx8q1fcOji9E5yQhhevatnsxy3wmhG7/mpMJirf8n/EReKt5N7NerLc/2fZzH184xGH7uttwYv3dod/Tv4wVenRnZBBdamnwYAPDKkI0qqTEg/WYgPfz2BLsHeGNcvHLGhetv+v58swDtbjmDbkXy7em/qEYLe4b4I0XtAqZDho19PYNfFqcN+UX7w0iix72wxzpXU/hK9lFopR3RbL9zWOxS3xLXDkbxSbD96AYM7t0VxpRGbD+Thuz/O2t67hrq+UwDOFlXi2Ply++Mp5DBaGl6XTAZEBXiiqMJ08QtEgQh/T3Rs6wl/z4tf+Do1Ejv6w0erwoVyAzw1SoS10UGjrP4wE6j7C0YIgSqTFaUGE17ZcAD/L/NsrTL9O/jhbFEVsgoq0EanwsI7e6LSaEFkgCfi2utRWGHC3jPFOJxbCqPFithQH6gVclwoN2LvmWIcOVcKq6j+HcwqqMC5EgO0Kjm8NKo6A06NPpFtUFBuxPH8clzrJ1V1qPTG0bwyqJRy3NwzBN1D9ThdWIk/ThchM6sIpRen7ry1SnRo6wUPlRxni6pwurACHioFOgd7w2CqHkUqM5jho1WhpNJk26/mOFYh4OepRrCPFhYhMKxLEKrMFpwuqERWQQVOXShHSdXf+/h5qhHqq0VOURUulBtrtV2tkEOjlKPUYIaXRon2bapHwKICPFFYYcLx82U4dr5xQc9bq0SIXguj2Qq9Tg0hBLw0SlwoM9o+n+qiUsjgqVGiqKI66PtolagyWxGi16Ksylxn++36opRDIZOh0mSBXAb4eWrQ1luDIB8NQvQeCNVr4aVVQqtSoH0bD7Tz9UC5wYIzRRVQKeQwW6vXBuo9VAjz06F9Gw+E6D0kHZ6KK0zILamCl1YJH60Snmql3edumcGMvJIqKOVyaFRynCupwon8cujUyuqw6Vn9B4+3VolyoxnZBZWoMlng46GCwWyBr4cagT4a+OnUKDOa8eOBPBzNK8MvR86jtMqM0ioTDCYr1Er5xfdaC61KjvOlBmRkF0EIwFujhEYlh8FkRZnRDLlMBovV/h+dSiFDG111+NUoq0fMA7yqf34eKgWO5pWhqMIIhVwGfy8Nlk9IcOj7yNDTBFIIPQs2HsB/fjkOAIgO9MLm6YOb5bip+8/hwVW7AQBKuQzmi7/QXz6ciL5RfrZyxZUmXCgz2I1+CCEw9YsMbPjz71GqLsHe6Bvlh+fGdMW6PadRbjDj051ZyCqoHh24uWcIYkP1mDggAjq1Y6bxhBA4fK4M24/mY0S3ILRv42H3l4cQAkfyyhDorYFvHfc+23roPDzUCpwprMR/fjlWK4w0xQ2d22Jc33AMjPZHfpkRWw6cQ/qpQkwZ3NG2gN1iFTBZrPgjuwjRgV7w81Qjq6AC/9uXi72ni5FdWIEygxnniqtQbvx7PUx0oBfOFFai0tS0NTIyGWxhQSmXoUuIN+LD26BPlB/6RvlB76HCre9tx8Fc+y+5maO6IMzPA7nFVfhnQhj0HtXTcAXlRmhV8mv+eV46RXWhzIADOaVQyGVQK2U4daECEf6euC7c1/azLTOY8deZYhjMVoT56XAwpwT5ZQacLqxEUmwQ5DIZ8koNKK4wwSIEQn09ENdeD72HCvllRnioFfC6OJVc35SY1SpwpqgS/l7qWv272n3zCsqNMFusKK402f7dXO1LuMxghtFshUohg7f272nOSqMFx86XITLAExqlHCWVJrTRqSGXy1Blslz8sqldd037j+SV4mheGQ6fK0NeqQHnSw04U1iBUoO5UcEx0l8HACipMsNgssByMRw3lEwG6FQKVJmtsFgFtCq500bflHIZQny18PPUoLSy+ndA76FCWJvqUNTeT4dgHy081QrodSr4aFWwWAUCvDW234vGMpgt2Hu6GIfPlaG0qnrJgL+XBkq5DAazFTnFlRenNqtswaKGXAZ4qqsDjFz292dxaxLso8XO54Y5tE6GniaQQuipNFrw6vcHbVNAabNuRKivB8wWa5Pn48sNZqTuP4cjeaV4dEh0nWuF3t1yBItSD+Ou+PYY3LktHv/i7xEblUKGcX3DcUuvdnhlw37sySrCjJExeHRIR8hkMpy6UI7Br/9sK7/xievRLbT2+2eyWFFWZYZOo2jS1Flzq/miOJpXhtNFlfgu8yx2nfx7kbmXpnpoHwCSugVhQEd/9InyQ1SAJ/JLjTieX4bBnds6dMi3pMqE344XoGNbT9sXaHZBBfZkFWLn8QsQAri5ZyjySqtw6kIFjuaVwXjxff/zdJFdaLoauQy4/PNWpZDhx6eHIMxP57A+ketVGM0oqjAh1NcDVSYLsgoqcDK/HMWVJmhVCmhVCpRWmVBmMCPS3xM3dG5rt7/VKlBpsqCo0oTiChOsQqCttwaFFUaoFHLkFFWhwmhGh7bV64uA6mBpNFdPlchlQKnBjJJKE8wWgQqjBb46FQorjMgrNeBccRXOFlchp6gSF8qNsAqBs0WVOF1YPaoR6K2Ft1YJnVphC4mnCytwpqgSJkvTv8Zq1mS1a+MBvYcKViHgqVbCV6eC3kMFHw8VvDVKeNoeChhMViQv29GoEKdWyiGEqLetchmgVSlQZbJAIZchOtAbaqUc+aUGFJQbIfB36PT3VCPQR4vc4sqLU42wG2Hz0SrRJ9IPnYOr1xT6earh66GC2Sps73VRpRFalQKxoXpE+utQXGmC0WKFVqm4OM1cfYJIhL8OZquAwWxFSWX1SHN+mQHFlSaoFHIUlBtxvtSA/DIDvLUq9ArzhUxW/TlyY5egJv9c6sLQ0wRSCD01bl+yHRlZRXjtzp7w81TjgVW78dpdPXF3Qlij6qkwmnHjG1uRW1IFABjRLajOYcWnv/wD6/acxoyRMXhsaDS+35eDKZ/uuWr9/4xvj9OFldhxvHpdzfIJCRjRzbG/zFKSXVCB308WYFjXIKgVcpwqKEdMkLdL57Ibymi24tj5MnQK9IJCLkN2QSUysgvh51k9RH48vwy/nyjA7ycLcSC3xPbX58M3dMB9/SOQXVCB9m10CPdn4CFpuNraH4tV4FxJFc4UVeJsUSUMJiva+mhgNFtxurAS2QUVOF1YifOlVdWhrcKEwgojzFZxzVOmANAp0Asd2nrCbBE4X2ZAaZUZKoUMKoUcWpUCfSL90C/KD0NiqkOkwWxFSZUJJZVmaFVyW2gJ0Wshu2RKqa7+mixWGM3WOv+oNVmsKKowQS6DbWSwtWHoaQIphZ6aBcE39QjBnqxC5BRXh5ZDL49q1CjJzuMXcM+ynXbbFif3wm292+HL3dlo66XB0C6BGP/Rb9h2JB+L/hmHO+PbA6geon3sswxsPnCuQccaEtMWK//Vt8FtI+kqqjBiT1YhArw06Nne19XNIWo2NV97ZQYzzhZV4UxRBc4UVaG4wgijRQBCoLjSVD2qVWlCWZUZZQYzyo1mVBiqL60hBPDqXT1we+/2Lu6N+3DE93fzni9NdobGtMU7W45g6+Hz8Lvk5qSb9+fhpp4h9e5nsQoo5DJUGi34/q8cnMj/+wybITFt8fOh85i2JhN5pVX498bat7y49FgapQIfTqweFaowVk+RfbjtBB4b2hEeaiWe/jIT+WV/D5s2dhSKpMtXp3b48DNRS1AzauutVSEmWIWY4MafQSuEaBGjv2SPIz0uZLUK9F+wxXbtjxq+OhU2TbsBQT5a27ZPd57CnP/uA1A9V5rYMQC/HD5vt9/o7sF4Z2xv/GvF7/j1qP1ZTpf672MD0euyK0TXx2KtnlcP8NIgr7QKEf6eDewdERGR4zji+5tXsXIhuVyG4XWsjSmqMGHs8p226ycAsAUeADBZRK3AAwBhfjqoFHKs+Fcf9O/gV+v1Gv6e6npfu5xCLkOYnw4eF0+RJiIiaqkYelxsVKz9zUhnjIwBABw/X463L7kAYFvv2ndsB4DYUJ+Lq/7l+NfASACASiHHyn/1xYyRMZhzU1cc+/cYnFgwBtNHdMYDg6LQvo2HczpDREQkYVzT42KJHf3hq1PZLvR1S1woPvj5GEoNZrz741HcnRCGMD8dPNUK1Izt1Fx7Ra2U4/8m9cHZokqoFHKE6P8OM1qVAo8NjbY71hPDOjVXt4iIiCSHocfFVAo5hsYE4puMMwAAHw8V/pyXhH9+sAO7TxXi3R+PYOEdPW23A1j/+CB0DfHBmcJKlBvNCPLR2q39ISIiorpxeksCLr3mjU5dfW+T527qCgD4cvdpzPvuL9vrbTzVUMhlCPfXoWuIaxdiExERtSQc6ZGAkbHBuPO69vD3UtsudX9deBtc3ykA247kY9WOv+9SHlTP2h4iIiK6Mo70SIBCLsOiu+Pw3Jiudtvn3tzN7vnrd/Vs8m0qiIiI3B2/QSWsU5A3Vj/U3/Y8kGt3iIiImoyhR+L6d/DHpAGR6Nlej4SINq5uDhERUYvFNT0twLxbYl3dBCIiohaPIz1ERETkFhh6iIiIyC0w9BAREZFbYOghIiIit8DQQ0RERG6BoYeIiIjcAkMPERERuQWGHiIiInILDD1ERETkFhh6iIiIyC0w9BAREZFbYOghIiIit8DQQ0RERG6BoYeIiIjcgtLVDWhuQggAQElJiYtbQkRERA1V871d8z3eFG4XekpLSwEAYWFhLm4JERERNVZpaSn0en2T9pWJa4lMLZDVasXZs2fh7e0NmUzm0LpLSkoQFhaG7Oxs+Pj4OLRuKXGHfrpDHwH2s7Vxh366Qx8B9rMuQgiUlpYiNDQUcnnTVue43UiPXC5H+/btnXoMHx+fVv1LWsMd+ukOfQTYz9bGHfrpDn0E2M/LNXWEpwYXMhMREZFbYOghIiIit8DQ40AajQYvvPACNBqNq5viVO7QT3foI8B+tjbu0E936CPAfjqL2y1kJiIiIvfEkR4iIiJyCww9RERE5BYYeoiIiMgtMPQQERGRW2DocZAlS5YgKioKWq0W8fHx2LZtm6ub1GALFixAnz594O3tjcDAQNx22204dOiQXRkhBObNm4fQ0FB4eHhgyJAh+Ouvv+zKGAwGPP744wgICICnpyduueUWnD59ujm70igLFiyATCbDtGnTbNtaSz/PnDmD++67D/7+/tDpdOjVqxfS09Ntr7eGfprNZsyZMwdRUVHw8PBAhw4dMH/+fFitVluZltbPX375Bf/4xz8QGhoKmUyG//73v3avO6o/hYWFGD9+PPR6PfR6PcaPH4+ioiIn9+5vV+qnyWTCzJkz0aNHD3h6eiI0NBQTJkzA2bNn7epo6f283MMPPwyZTIbFixfbbW8t/Txw4ABuueUW6PV6eHt7o3///sjKyrK93mz9FHTNVq9eLVQqlVi+fLnYv3+/ePLJJ4Wnp6c4deqUq5vWICNHjhQrVqwQ+/btE5mZmeKmm24S4eHhoqyszFZm4cKFwtvbW6xbt07s3btXJCcni5CQEFFSUmIrM2XKFNGuXTuRmpoq9uzZI4YOHSri4uKE2Wx2RbeuaNeuXSIyMlL07NlTPPnkk7btraGfBQUFIiIiQkyaNEn89ttv4sSJE2Lz5s3i6NGjtjKtoZ8vv/yy8Pf3F+vXrxcnTpwQX331lfDy8hKLFy+2lWlp/dy4caNISUkR69atEwDEN998Y/e6o/ozatQo0b17d5GWlibS0tJE9+7dxc0339xc3bxiP4uKisTw4cPFmjVrxMGDB8WOHTtEv379RHx8vF0dLb2fl/rmm29EXFycCA0NFW+99Zbda62hn0ePHhV+fn5ixowZYs+ePeLYsWNi/fr14ty5c7YyzdVPhh4H6Nu3r5gyZYrdti5duohZs2a5qEXXJi8vTwAQW7duFUIIYbVaRXBwsFi4cKGtTFVVldDr9eKDDz4QQlR/UKlUKrF69WpbmTNnzgi5XC6+//775u3AVZSWlopOnTqJ1NRUMXjwYFvoaS39nDlzphg0aFC9r7eWft50003i/vvvt9t2xx13iPvuu08I0fL7efmXh6P6s3//fgFA7Ny501Zmx44dAoA4ePCgk3tV25XCQI1du3YJALY/JFtTP0+fPi3atWsn9u3bJyIiIuxCT2vpZ3Jysu3fZV2as5+c3rpGRqMR6enpSEpKstuelJSEtLQ0F7Xq2hQXFwMA/Pz8AAAnTpxAbm6uXR81Gg0GDx5s62N6ejpMJpNdmdDQUHTv3l1y78Njjz2Gm266CcOHD7fb3lr6+e233yIhIQH//Oc/ERgYiN69e2P58uW211tLPwcNGoQtW7bg8OHDAIA//vgDv/76K8aMGQOg9fSzhqP6s2PHDuj1evTr189Wpn///tDr9ZLrc43i4mLIZDL4+voCaD39tFqtGD9+PGbMmIHY2Nhar7eGflqtVmzYsAGdO3fGyJEjERgYiH79+tlNgTVnPxl6rlF+fj4sFguCgoLstgcFBSE3N9dFrWo6IQSmT5+OQYMGoXv37gBg68eV+pibmwu1Wo02bdrUW0YKVq9ejfT0dCxYsKDWa62ln8ePH8fSpUvRqVMnbNq0CVOmTMETTzyBVatWAWg9/Zw5cybGjh2LLl26QKVSoXfv3pg2bRrGjh0LoPX0s4aj+pObm4vAwMBa9QcGBkquzwBQVVWFWbNmYdy4cbYbUraWfr766qtQKpV44okn6ny9NfQzLy8PZWVlWLhwIUaNGoUffvgBt99+O+644w5s3boVQPP20+3usu4sMpnM7rkQota2lmDq1Kn4888/8euvv9Z6rSl9lNL7kJ2djSeffBI//PADtFptveVaej+tVisSEhLw73//GwDQu3dv/PXXX1i6dCkmTJhgK9fS+7lmzRp8+umn+PzzzxEbG4vMzExMmzYNoaGhmDhxoq1cS+/n5RzRn7rKS7HPJpMJ99xzD6xWK5YsWXLV8i2pn+np6Xj77bexZ8+eRrenJfWz5sSCW2+9FU899RQAoFevXkhLS8MHH3yAwYMH17uvM/rJkZ5rFBAQAIVCUStp5uXl1fqLTOoef/xxfPvtt/jpp5/Qvn172/bg4GAAuGIfg4ODYTQaUVhYWG8ZV0tPT0deXh7i4+OhVCqhVCqxdetWvPPOO1AqlbZ2tvR+hoSEoFu3bnbbunbtajtTorX8PGfMmIFZs2bhnnvuQY8ePTB+/Hg89dRTtlG81tLPGo7qT3BwMM6dO1er/vPnz0uqzyaTCXfffTdOnDiB1NRU2ygP0Dr6uW3bNuTl5SE8PNz2eXTq1Ck8/fTTiIyMBNA6+hkQEAClUnnVz6Tm6idDzzVSq9WIj49Hamqq3fbU1FQMGDDARa1qHCEEpk6diq+//ho//vgjoqKi7F6PiopCcHCwXR+NRiO2bt1q62N8fDxUKpVdmZycHOzbt08y78OwYcOwd+9eZGZm2h4JCQm49957kZmZiQ4dOrSKfg4cOLDWJQcOHz6MiIgIAK3n51lRUQG53P4jTKFQ2P6ybC39rOGo/iQmJqK4uBi7du2ylfntt99QXFwsmT7XBJ4jR45g8+bN8Pf3t3u9NfRz/Pjx+PPPP+0+j0JDQzFjxgxs2rQJQOvop1qtRp8+fa74mdSs/WzwkmeqV80p6x999JHYv3+/mDZtmvD09BQnT550ddMa5JFHHhF6vV78/PPPIicnx/aoqKiwlVm4cKHQ6/Xi66+/Fnv37hVjx46t81TZ9u3bi82bN4s9e/aIG2+8UVKnONfl0rO3hGgd/dy1a5dQKpXilVdeEUeOHBGfffaZ0Ol04tNPP7WVaQ39nDhxomjXrp3tlPWvv/5aBAQEiGeffdZWpqX1s7S0VGRkZIiMjAwBQLz55psiIyPDdtaSo/ozatQo0bNnT7Fjxw6xY8cO0aNHj2Y9xflK/TSZTOKWW24R7du3F5mZmXafSQaDodX0sy6Xn70lROvo59dffy1UKpVYtmyZOHLkiHj33XeFQqEQ27Zta/Z+MvQ4yPvvvy8iIiKEWq0W1113ne1075YAQJ2PFStW2MpYrVbxwgsviODgYKHRaMQNN9wg9u7da1dPZWWlmDp1qvDz8xMeHh7i5ptvFllZWc3cm8a5PPS0ln5+9913onv37kKj0YguXbqIZcuW2b3eGvpZUlIinnzySREeHi60Wq3o0KGDSElJsftibGn9/Omnn+r8tzhx4kQhhOP6c+HCBXHvvfcKb29v4e3tLe69915RWFjYTL28cj9PnDhR72fSTz/91Gr6WZe6Qk9r6edHH30koqOjhVarFXFxceK///2vXR3N1U+ZEEI0fFyIiIiIqGXimh4iIiJyCww9RERE5BYYeoiIiMgtMPQQERGRW2DoISIiIrfA0ENERERugaGHiIiI3AJDDxEREbkFhh4icrqVK1fC19e3Sfs+//zzeOihhxzboGv0888/QyaToaioqNmPvX79evTu3dt2jzEiajiGHiI3MWnSJMhkMtvD398fo0aNwp9//tmoeubNm4devXo5p5GXOXfuHN5++20899xzzXI8Z3vllVcwYMAA6HS6ekPgli1bMGDAAHh7eyMkJAQzZ86E2Wy2vX7zzTdDJpPh888/b6ZWE7UeDD1EbmTUqFHIyclBTk4OtmzZAqVSiZtvvtnVzarXRx99hMTERERGRrq6KQ5hNBrxz3/+E4888kidr//5558YM2YMRo0ahYyMDKxevRrffvstZs2aZVfuX//6F959993maDJRq8LQQ+RGNBoNgoODERwcjF69emHmzJnIzs7G+fPnbWVmzpyJzp07Q6fToUOHDnj++edhMpkAVE9Tvfjii/jjjz9sI0YrV64EABQVFeGhhx5CUFAQtFotunfvjvXr19sdf9OmTejatSu8vLxsAexKVq9ejVtuucVumxACr732Gjp06AAPDw/ExcVh7dq1ttdrpp42bNiAuLg4aLVa9OvXD3v37rWrZ926dYiNjYVGo0FkZCQWLVpk97rBYMCzzz6LsLAwaDQadOrUCR999JFdmfT0dCQkJECn02HAgAE4dOjQFfvz4osv4qmnnkKPHj3q7W/Pnj0xd+5cREdHY/DgwViwYAHef/99lJaW2srdcsst2LVrF44fP37F4xGRPYYeIjdVVlaGzz77DNHR0fD397dt9/b2xsqVK7F//368/fbbWL58Od566y0AQHJyMp5++mnExsbaRoySk5NhtVoxevRopKWl4dNPP8X+/fuxcOFCKBQKW70VFRV444038Mknn+CXX35BVlYWnnnmmXrbV1hYiH379iEhIcFu+5w5c7BixQosXboUf/31F5566incd9992Lp1q125GTNm4I033sDvv/+OwMBA3HLLLbbwlp6ejrvvvhv33HMP9u7di3nz5uH555+3BTgAmDBhAlavXo133nkHBw4cwAcffAAvLy+7Y6SkpGDRokXYvXs3lEol7r///sb9EC5jMBig1Wrttnl4eKCqqgrp6em2bREREQgMDMS2bduu6XhEbqdJ95EnohZn4sSJQqFQCE9PT+Hp6SkAiJCQEJGenn7F/V577TURHx9ve/7CCy+IuLg4uzKbNm0ScrlcHDp0qM46VqxYIQCIo0eP2ra9//77IigoqN7jZmRkCAAiKyvLtq2srExotVqRlpZmV3by5Mli7NixQgghfvrpJwFArF692vb6hQsXhIeHh1izZo0QQohx48aJESNG2NUxY8YM0a1bNyGEEIcOHRIARGpqap1tqznG5s2bbds2bNggAIjKysp6+1RjxYoVQq/X19pe8z5+/vnnwmw2i9OnT4tBgwYJAOLzzz+3K9u7d28xb968qx6LiP7GkR4iNzJ06FBkZmYiMzMTv/32G5KSkjB69GicOnXKVmbt2rUYNGgQgoOD4eXlheeffx5ZWVlXrDczMxPt27dH586d6y2j0+nQsWNH2/OQkBDk5eXVW76yshIA7EY+9u/fj6qqKowYMQJeXl62x6pVq3Ds2DG7/RMTE23/7+fnh5iYGBw4cAAAcODAAQwcONCu/MCBA3HkyBFYLBZkZmZCoVBg8ODBV+x3z5497foD4Ip9upqkpCS8/vrrmDJlCjQaDTp37oybbroJAOxGzYDqEaCKioomH4vIHTH0ELkRT09PREdHIzo6Gn379sVHH32E8vJyLF++HACwc+dO3HPPPRg9ejTWr1+PjIwMpKSkwGg0XrFeDw+Pqx5bpVLZPZfJZBBC1Fs+ICAAQPU0V42a07Q3bNhgC2+ZmZnYv3+/3bqe+shkMgDV64Jq/r/GpW1pSH8A+z7V1Hetp5JPnz4dRUVFyMrKQn5+Pm699VYAQFRUlF25goICtG3b9pqOReRulK5uABG5jkwmg1wut42qbN++HREREUhJSbGVuXQUCADUajUsFovdtp49e+L06dM4fPjwFUd7GqNjx47w8fHB/v37bXV269YNGo0GWVlZVx2F2blzJ8LDwwFUB6fDhw+jS5cutnp+/fVXu/JpaWno3LkzFAoFevToAavViq1bt2L48OEO6U9jyGQyhIaGAgC++OILhIWF4brrrrO9XlVVhWPHjqF3797N3jailoyhh8iNGAwG5ObmAqgOAu+99x7Kysrwj3/8AwAQHR2NrKwsrF69Gn369MGGDRvwzTff2NURGRmJEydO2Ka0vL29MXjwYNxwww2488478eabbyI6OhoHDx6ETCbDqFGjmtRWuVyO4cOH49dff8Vtt90GoHqR9TPPPIOnnnoKVqsVgwYNQklJCdLS0uDl5YWJEyfa9p8/fz78/f0RFBSElJQUBAQE2Op5+umn0adPH7z00ktITk7Gjh078N5772HJkiW2Pk6cOBH3338/3nnnHcTFxeHUqVPIy8vD3Xff3aT+AEBWVhYKCgqQlZVlm0YDqt/3mkXSr7/+OkaNGgW5XI6vv/4aCxcuxJdffmk3vbVz505oNBq7KTwiagAXrykiomYyceJEAcD28Pb2Fn369BFr1661Kzdjxgzh7+8vvLy8RHJysnjrrbfsFt1WVVWJO++8U/j6+goAYsWKFUKI6sXC//rXv4S/v7/QarWie/fuYv369UKIuhfufvPNN+JqH0Hff/+9aNeunbBYLLZtVqtVvP322yImJkaoVCrRtm1bMXLkSLF161YhxN+LjL/77jsRGxsr1Gq16NOnj8jMzLSre+3ataJbt25CpVKJ8PBw8frrr9u9XllZKZ566ikREhIi1Gq1iI6OFv/3f/9nd4zCwkJb+ZqF1ydOnKi3P5f/DGoeP/30k63M0KFDhV6vF1qtVvTr109s3LixVj0PPfSQePjhh6/43hFRbTIhrjCpTkTkQkII9O/fH9OmTcPYsWMbtM/PP/+MoUOHorCwsMm3vpCy8+fPo0uXLti9e3etdT5EdGVcyExEkiWTybBs2TK72zC4uxMnTmDJkiUMPERNwJEeImpVWvtIDxE1HUMPERERuQVObxEREZFbYOghIiIit8DQQ0RERG6BoYeIiIjcAkMPERERuQWGHiIiInILDD1ERETkFhh6iIiIyC38f/JB4Cs1C1StAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=20,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2947 - accuracy: 0.9121 - val_loss: 0.1499 - val_accuracy: 0.9564\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.1635 - accuracy: 0.9540 - val_loss: 0.1220 - val_accuracy: 0.9666\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1377 - accuracy: 0.9626 - val_loss: 0.1143 - val_accuracy: 0.9707\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1265 - accuracy: 0.9681 - val_loss: 0.1109 - val_accuracy: 0.9729\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1188 - accuracy: 0.9708 - val_loss: 0.1128 - val_accuracy: 0.9741\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1161 - accuracy: 0.9713 - val_loss: 0.1107 - val_accuracy: 0.9766\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1062 - accuracy: 0.9746 - val_loss: 0.1202 - val_accuracy: 0.9744\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1022 - accuracy: 0.9768 - val_loss: 0.1102 - val_accuracy: 0.9785\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.0968 - accuracy: 0.9776 - val_loss: 0.1210 - val_accuracy: 0.9767\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0972 - accuracy: 0.9786 - val_loss: 0.1136 - val_accuracy: 0.9787\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0920 - accuracy: 0.9797 - val_loss: 0.1197 - val_accuracy: 0.9786\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0889 - accuracy: 0.9812 - val_loss: 0.1314 - val_accuracy: 0.9776\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0879 - accuracy: 0.9807 - val_loss: 0.1160 - val_accuracy: 0.9796\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0845 - accuracy: 0.9822 - val_loss: 0.1315 - val_accuracy: 0.9787\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0803 - accuracy: 0.9826 - val_loss: 0.1388 - val_accuracy: 0.9782\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0890 - accuracy: 0.9822 - val_loss: 0.1367 - val_accuracy: 0.9795\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0808 - accuracy: 0.9833 - val_loss: 0.1326 - val_accuracy: 0.9793\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0763 - accuracy: 0.9844 - val_loss: 0.1244 - val_accuracy: 0.9806\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0766 - accuracy: 0.9843 - val_loss: 0.1321 - val_accuracy: 0.9796\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0732 - accuracy: 0.9855 - val_loss: 0.1319 - val_accuracy: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a81f3cc880>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=20,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 16716), started 0:11:30 ago. (Use '!kill 16716' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4b1a9feed198c245\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4b1a9feed198c245\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9139\n",
      "...loss: 0.2916\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9523\n",
      "...loss: 0.1686\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9625\n",
      "...loss: 0.1409\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9679\n",
      "...val_loss: 0.1308\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9679\n",
      "...val_loss: 0.1308\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2931\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1648\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1369\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1260\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a81bfda070>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 0.2948 - sparse_categorical_accuracy: 0.9127\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1669 - sparse_categorical_accuracy: 0.9528\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1396 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1255 - sparse_categorical_accuracy: 0.9687\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1161 - sparse_categorical_accuracy: 0.9707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a81d5132e0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
